# ==============================================================================
# RustBlogCMS - Docker Compose Nginx Configuration
# ==============================================================================
#
# This Nginx configuration acts as a reverse proxy and load balancer for the
# RustBlogCMS application running inside Docker Compose. It routes requests
# between the frontend and backend services while providing security features
# and performance optimizations.
#
# Architecture:
# - Frontend: React/Vite application (port 80)
# - Backend: Rust API service (port 8489)
# - Nginx: Reverse proxy on port 80
#
# Features:
# - Load balancing with health checks
# - WebSocket support for real-time features
# - Proper HTTP headers for security and forwarding
# - Connection pooling for improved performance
# - Comprehensive logging and monitoring
#
# Environment: Docker Compose internal network
# @version 1.0.0
# @author RustBlogCMS Team
# ==============================================================================

# ==============================================================================
# WEBSOCKET UPGRADE HANDLING
# ==============================================================================

# Map directive for conditional WebSocket upgrade detection
# This enables WebSocket connections when the Upgrade header is present
# while maintaining regular HTTP connections for standard requests
map $http_upgrade $connection_upgrade {
    default upgrade;    # Upgrade to WebSocket when header is present
    '' close;          # Close connection for regular HTTP requests
}

# ==============================================================================
# UPSTREAM SERVER DEFINITIONS
# ==============================================================================

# Backend API server configuration
# Routes to the Rust backend service running in Docker
upstream backend {
    # Backend service endpoint (Docker service name:port)
    server backend:8489 max_fails=3 fail_timeout=30s;

    # Connection pooling for improved performance
    # Maintains persistent connections to reduce overhead
    keepalive 32;

    # Additional upstream options (consider adding):
    # least_conn;          # Load balancing by least connections
    # backup;              # Mark as backup server
    # down;                # Temporarily mark server as down
    # weight 1;           # Server weight for load balancing
    # max_conns 100;      # Maximum connections per server
}

# Frontend web server configuration
# Routes to the Nginx frontend service serving static files
upstream frontend {
    # Frontend service endpoint (Docker service name:port)
    server frontend:80 max_fails=3 fail_timeout=30s;

    # Connection pooling for static file serving
    # Fewer connections needed for static content
    keepalive 16;

    # Load balancing options for frontend:
    # Consider multiple frontend instances for high availability
    # server frontend2:80 backup;  # Add backup frontend instance
}

# ==============================================================================
# MAIN SERVER CONFIGURATION
# ==============================================================================

server {
    # ========================================================================
    # SERVER LISTENING CONFIGURATION
    # ========================================================================

    # Listen on port 80 for HTTP traffic
    # In production, consider SSL termination at load balancer
    listen 80;

    # Server name for virtual hosting
    # Update this for production domain names
    server_name localhost;

    # ========================================================================
    # LOGGING CONFIGURATION
    # ========================================================================

    # Access logging for request tracking and analytics
    # Consider custom log formats for better monitoring
    access_log /var/log/nginx/access.log;

    # Error logging for troubleshooting
    # Set to 'warn' or 'error' in production to reduce log volume
    error_log /var/log/nginx/error.log;

    # ========================================================================
    # SECURITY CONFIGURATION
    # ========================================================================

    # Hide Nginx version information for security
    # Prevents attackers from knowing server version
    server_tokens off;

    # Maximum request body size
    # Important for file uploads and large tutorial content
    client_max_body_size 10M;

    # Security headers - applied globally to all responses
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "0" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    add_header Permissions-Policy "geolocation=(), microphone=(), camera=()" always;

    # ========================================================================
    # API ROUTING CONFIGURATION
    # ========================================================================

    # ========================================================================
    # LOGIN RATE LIMITING (STRICT)
    # ========================================================================
    
    # Stricter rate limiting for authentication endpoints
    # 5 requests per minute to prevent brute-force attacks
    location = /api/auth/login {
        limit_req zone=login burst=3 nodelay;
        
        proxy_pass http://backend/api/auth/login;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Route all API requests to the backend service
    location /api/ {
        # Rate limiting: 10 req/s with burst of 20
        limit_req zone=api burst=20 nodelay;
        
        # Proxy to backend upstream server
        proxy_pass http://backend/api/;

        # Use HTTP/1.1 for better proxy functionality
        proxy_http_version 1.1;

        # ====================================================================
        # PROXY HEADERS - API REQUESTS
        # ====================================================================

        # Standard proxy headers for proper request forwarding
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # ====================================================================
        # TIMEOUT CONFIGURATION
        # ====================================================================

        # Extended timeouts for large tutorial content and processing
        # Adjust based on your application's performance characteristics
        proxy_connect_timeout 120s;  # Time to establish connection
        proxy_send_timeout 120s;     # Time to send request
        proxy_read_timeout 120s;     # Time to read response

        # ====================================================================
        # WEBSOCKET SUPPORT
        # ====================================================================

        # Conditional WebSocket upgrade support
        # Enables real-time features when needed
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;

        # Additional proxy options for API:
        # proxy_buffering off;        # Disable for streaming responses
        # proxy_cache_bypass $http_upgrade;  # Bypass cache for WebSockets
        # proxy_request_buffering off;  # Disable for large uploads
    }

    # ========================================================================
    # UPLOADS ROUTING CONFIGURATION
    # ========================================================================

    # Route upload requests to the backend service
    location ^~ /uploads/ {
        # Proxy to backend upstream server
        proxy_pass http://backend/uploads/;

        # Use HTTP/1.1 for better proxy functionality
        proxy_http_version 1.1;

        # Standard proxy headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # ========================================================================
    # FRONTEND ROUTING CONFIGURATION
    # ========================================================================

    # Route root and page requests to the backend for server-side injection
    # This allows the backend to inject dynamic meta tags into index.html
    location / {
        # Proxy to backend upstream server
        proxy_pass http://backend;

        # Use HTTP/1.1 for consistent behavior
        proxy_http_version 1.1;

        # Standard proxy headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Route static assets to the frontend service directly
    # This bypasses the backend for better performance on static files
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|json|xml|txt|map)$ {
        proxy_pass http://frontend;
        proxy_http_version 1.1;
        
        # Standard proxy headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Caching headers for static assets
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # ========================================================================
    # HEALTH CHECK ENDPOINT
    # ========================================================================

    # Simple health check for monitoring systems
    # Used by container orchestration and load balancers
    location /health {
        # Disable access logging for health checks
        access_log off;

        # Return simple healthy response
        return 200 "healthy\n";
        add_header Content-Type text/plain;

        # Consider adding more detailed health information:
        # access_log off;
        # default_type application/json;
        # return 200 '{"status":"healthy","timestamp":"$time_iso8601"}';
    }

    # ========================================================================
    # ADDITIONAL LOCATION BLOCKS (Optional)
    # ========================================================================

    # Consider adding these location blocks for enhanced functionality:

    # Static assets direct serving (bypass frontend for better performance):
    # location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
    #     proxy_pass http://frontend;
    #     expires 1y;
    #     add_header Cache-Control "public, immutable";
    # }

    # Admin area with additional security:
    # location /admin/ {
    #     proxy_pass http://frontend;
    #     # Add IP restrictions or authentication
    #     # allow 192.168.1.0/24;
    #     # deny all;
    # }

    # API rate limiting:
    # location /api/ {
    #     limit_req zone=api burst=20 nodelay;
    #     # ... rest of API configuration
    # }

    # Maintenance page:
    # location /maintenance.html {
    #     root /usr/share/nginx/html;
    # }
    #
    # error_page 503 /maintenance.html;
}

# ==============================================================================
# RATE LIMITING CONFIGURATION (ACTIVE)
# ==============================================================================

# Rate limiting zones for protection against abuse
# These are defined in the http block context
#
# To activate, add this to /etc/nginx/nginx.conf in the http {} block:
#
#   # Limit API requests to 10 per second with burst of 20
#   limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
#
#   # Limit login attempts to 5 per minute
#   limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;
#
#   # Limit search to 3 per second (prevents scraping)
#   limit_req_zone $binary_remote_addr zone=search:10m rate=3r/s;
#
# Then apply in location blocks:
#   location /api/auth/login {
#       limit_req zone=login burst=3 nodelay;
#       ...
#   }
#   location /api/search {
#       limit_req zone=search burst=5 nodelay;
#       ...
#   }
#   location /api/ {
#       limit_req zone=api burst=20 nodelay;
#       ...
#   }

# ==============================================================================
# PERFORMANCE TUNING RECOMMENDATIONS
# ==============================================================================

# For production environments, consider these optimizations:
#
# 1. Worker Processes:
#    worker_processes auto;  # Match CPU cores
#    worker_connections 1024;  # Connections per worker
#
# 2. File Descriptors:
#    worker_rlimit_nofile 65535;  # Increase file descriptor limit
#
# 3. Keepalive Connections:
#    keepalive_timeout 65;
#    keepalive_requests 100;
#
# 4. Buffer Sizes:
#    client_body_buffer_size 128k;
#    client_max_body_size 10m;
#    client_header_buffer_size 1k;
#    large_client_header_buffers 4 4k;
#
# 5. Gzip Compression:
#    gzip on;
#    gzip_vary on;
#    gzip_min_length 1000;
#    gzip_types text/plain text/css application/json application/javascript;

# ==============================================================================
# MONITORING AND DEBUGGING
# ==============================================================================

# For enhanced monitoring, consider:
#
# 1. Custom Log Formats:
#    log_format detailed '$remote_addr - $remote_user [$time_local] '
#                       '"$request" $status $body_bytes_sent '
#                       '"$http_referer" "$http_user_agent" '
#                       'rt=$request_time uct="$upstream_connect_time" '
#                       'uht="$upstream_header_time" urt="$upstream_response_time"';
#
# 2. Status Monitoring:
#    location /nginx_status {
#        stub_status on;
#        access_log off;
#        allow 127.0.0.1;
#        deny all;
#    }
#
# 3. Request Timing:
#    add_header X-Response-Time $request_time always;
#    add_header X-Upstream-Time $upstream_response_time always;
